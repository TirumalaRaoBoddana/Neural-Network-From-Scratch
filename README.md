# Neural Network From Scratch

This repository contains a **Python implementation of a feedforward neural network built from scratch**. It demonstrates the fundamentals of neural networks, including forward propagation, backpropagation, gradient descent, and loss computation â€” all **without using high-level libraries** like TensorFlow or PyTorch.

## Features
- Fully connected neural network
- Forward propagation with **ReLU** (hidden layers) and **Sigmoid** (output layer)
- Loss computation:
  - **Binary Cross-Entropy** for classification
  - **Mean Squared Error** for regression
- Backpropagation with manual gradient computation
- Gradient descent optimization
- Example Jupyter Notebook included for testing

## Installation
Clone the repository:
```bash
git clone https://github.com/TirumalaRaoBoddana/Neural-Network-From-Scratch.git
cd Neural-Network-From-Scratch
